## Evaluation for CommonGen

We have intergate all evaluation metric into a single script, and thus we can evaluate each model with all metrics with a commandline as follows (or w/ `bash run_all_eval.sh`). **Please run the installation scripts that are in the readme of each folder (`Traditional`,`BERTScore`, and `PivotScore`).**  Also, please install `ROUGE` following the instructions at `rouge_install_instruction.md`.
 
The `csqa` folder contains the code for transferring study (Section 5.3).


The `human_evaluation` folder contains the human evaluation results adn scripts for computing inter-annotator agreement.